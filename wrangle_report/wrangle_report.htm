<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Microsoft Word - wrangle_report.docx</title><meta name="author" content="abdel"/><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 .s1 { color: #FFF; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 13pt; }
 h2 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 19pt; }
 .s2 { color: #4471C4; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 h1 { color: #4471C4; font-family:Arial, sans-serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 20.5pt; }
 .s3 { color: #4471C4; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 p { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; margin:0pt; }
 .s4 { color: #4E4E4E; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s5 { color: #4E4E4E; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11pt; }
 .s6 { color: #017A9B; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 11pt; }
 .s7 { color: #4471C4; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: underline; font-size: 10pt; }
 .s8 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11pt; }
 .s9 { color: #0563C1; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10pt; }
 .s10 { color: #017A9B; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10pt; }
 li {display: block; }
 #l1 {padding-left: 0pt;counter-reset: c1 0; }
 #l1> li:before {counter-increment: c1; content: counter(c1, decimal)". "; color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 li {display: block; }
 #l2 {padding-left: 0pt;counter-reset: d1 0; }
 #l2> li:before {counter-increment: d1; content: counter(d1, decimal)"- "; color: #4471C4; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l3 {padding-left: 0pt;counter-reset: e1 0; }
 #l3> li:before {counter-increment: e1; content: counter(e1, lower-latin)") "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l4 {padding-left: 0pt;counter-reset: f1 0; }
 #l4> li:before {counter-increment: f1; content: counter(f1, upper-roman)". "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l5 {padding-left: 0pt;counter-reset: g1 0; }
 #l5> li:before {counter-increment: g1; content: counter(g1, upper-roman)". "; color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
</style></head><body><p style="text-indent: 0pt;text-align: left;"><span><img width="644" height="1002" alt="image" src="wrangle_report/Image_001.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-left: 98pt;text-indent: 0pt;text-align: left;">10/17/2020</p><h2 style="padding-top: 4pt;padding-left: 52pt;text-indent: 0pt;text-align: left;">Data Wrangling Report</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s2" style="padding-top: 4pt;padding-left: 104pt;text-indent: 0pt;text-align: left;">Abdelrazek Rizk</p><p style="padding-left: 44pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="519" height="1" alt="image" src="wrangle_report/Image_002.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-top: 4pt;padding-left: 127pt;text-indent: 0pt;text-align: left;">Data Wrangling Report</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 44pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="519" height="1" alt="image" src="wrangle_report/Image_003.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s3" style="padding-top: 14pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">About the Dataset(s)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l1"><li style="padding-left: 39pt;text-indent: -16pt;text-align: left;"><p style="display: inline;">Twitter archive for <span style=" color: #4E4E4E;">WeRateDogs account.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The dataset that you will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user <span class="s6">@dog_rates</span>, also known as <span class="s6">WeRateDogs</span>. WeRateDogs is a Twitter account that rates people&#39;s dogs with a humorous comment about the dog.</p><p class="s5" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">WeRateDogs has over 4 million followers and has received international media coverage. This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 39pt;text-indent: -16pt;text-align: left;"><p style="display: inline;">Image Predictions File.</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The dataset is table full of image predictions (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l2"><li style="padding-left: 39pt;text-indent: -16pt;text-align: left;"><p class="s7" style="display: inline;">Gathering Data for this Project:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l3"><li style="padding-top: 4pt;padding-left: 42pt;text-indent: -16pt;text-align: left;"><p class="s8" style="display: inline;">downloaded the Twitter archive <span class="s9">https://support.twitter.com/articles/20170160</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-top: 5pt;padding-left: 48pt;text-indent: -22pt;text-align: left;"><p style="display: inline;">downloaded the tweet image predictions file <span style=" color: #4E4E4E;">using the </span>Requests <span style=" color: #4E4E4E;">library</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s9" style="padding-left: 42pt;text-indent: 2pt;text-align: left;">https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image- predictions/image-predictions.tsv</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-top: 4pt;padding-left: 42pt;text-indent: -16pt;text-align: left;"><p class="s4" style="display: inline;">Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet&#39;s JSON data using Python&#39;s <span class="s10">Tweepy </span>library and store each tweet&#39;s entire set of JSON data in a file called <span class="s8">“tweet_json.txt”</span></p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Gathering process:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l4"><li style="padding-top: 5pt;padding-left: 39pt;text-indent: -22pt;text-align: left;"><p style="display: inline;">Make Directory for my work space</p></li><li style="padding-left: 39pt;text-indent: -26pt;text-align: left;"><p style="display: inline;">Imported library <span class="s5">pandas NumPy requests tweepy json nbconvert pyppeteer pandocfilter s</span></p></li><li style="padding-left: 39pt;text-indent: -28pt;text-align: left;"><p style="display: inline;">Imported functions</p></li><li style="padding-left: 39pt;text-indent: -29pt;text-align: left;"><p style="display: inline;">Read twitter-archive-enhanced as pandas data frame and quick check to view structure</p></li><li style="padding-left: 39pt;text-indent: -26pt;text-align: left;"><p style="display: inline;">Download tweet image predictions TSV using the Requests library and write it to image_predictions.tsv</p></li><li style="padding-left: 39pt;text-indent: -29pt;text-align: left;"><p style="display: inline;">Query Twitter API for each tweet in the Twitter archive and save JSON in a text file read tweet&#39;s JSON data line by line and convert to a Data Frame</p></li></ol><p style="padding-left: 39pt;text-indent: 0pt;text-align: left;">Create a Data Frame with ‘created_at’&#39;,&#39;tweet_id&#39;,&#39;place&#39;,&#39;retweet_count&#39;, &#39;favorite_count&#39;, &#39;display_text_range</p></li><li style="padding-top: 3pt;padding-left: 39pt;text-indent: -16pt;text-align: left;"><p class="s7" style="display: inline;">Assessing Data for this Project:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Using panda data frame function df .info (), df.value_counts (), df.columns, df.dtypes To explore quality issues</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 39pt;text-indent: -16pt;text-align: left;"><p class="s7" style="display: inline;">Cleaning Data for this Project:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l5"><li style="padding-top: 4pt;padding-left: 39pt;text-indent: -22pt;text-align: left;"><p style="display: inline;">Make copy to my dataset</p></li><li style="padding-left: 39pt;text-indent: -25pt;text-align: left;"><p style="display: inline;">Drop Rows with Missing Values</p></li><li style="padding-left: 39pt;text-indent: -28pt;text-align: left;"><p style="display: inline;">replace unknown name like “a” with name &quot;apple&quot;</p></li><li style="padding-left: 39pt;text-indent: -29pt;text-align: left;"><p style="display: inline;">Drop empty column with null Values</p></li><li style="padding-left: 39pt;text-indent: -26pt;text-align: left;"><p style="display: inline;">Crete stages_of_dog column to marge &#39;doggo&#39;, &#39;floofer&#39;, &#39;pupper&#39;, &#39;puppo&#39;</p></li><li style="padding-left: 39pt;text-indent: -29pt;text-align: left;"><p style="display: inline;">replace URL source by the main source</p></li><li style="padding-left: 39pt;text-indent: -32pt;text-align: left;"><p style="display: inline;">Marge all data set in one data frame main_df.csv</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 39pt;text-indent: -16pt;text-align: left;"><p class="s7" style="display: inline;">Reporting for this Project</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 28pt;text-indent: -3pt;text-align: left;">Create a word written report called wrangle_report.pdf <span style=" color: #4E4E4E;">describes my wrangling efforts</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;text-align: left;">Create a word-minimum written report called act_report.pdf</p><p style="padding-left: 20pt;text-indent: 0pt;text-align: left;">that communicates the insights and displays the visualization(s) produced from my wrangled data</p></body></html>
